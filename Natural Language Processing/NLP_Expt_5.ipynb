{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJnUIf0dztcv",
        "outputId": "ca1bc591-e281-4fc7-b51a-31cbedefb8ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP Expt 5\n",
            "Dhwaj Jain S012\n"
          ]
        }
      ],
      "source": [
        "print(\"NLP Expt 5\")\n",
        "print(\"Dhwaj Jain S012\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "%pip install contractions\n",
        "import contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZZRomNpz0va",
        "outputId": "0a51a946-e36c-48dd-8a25-e12d2589a0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2cjy-WI0BOA",
        "outputId": "ed8141f6-17e5-4593-9dd2-79a742efd1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "   \"Call me Ishmael. Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world. It is a way I have of driving off the spleen and regulating the circulation. Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking people’s hats off—then, I account it high time to get to sea as soon as I can. This is my substitute for pistol and ball. With a philosophical flourish Cato throws himself upon his sword; I quietly take to the ship. There is nothing surprising in this. If they but knew it, almost all men in their degree, some time or other, cherish very nearly the same feelings towards the ocean with me. There now is your insular city of the Manhattoes, belted round by wharves as Indian isles by coral reefs—commerce surrounds it with her surf. Right and left, the streets take you waterward. Its extreme downtown is the battery, where that noble mole is washed by waves, and cooled by breezes, which a few hours previous were out of sight of land. Look at the crowds of water-gazers there. Circumambulate the city of a dreamy Sabbath afternoon. Go from Corlears Hook to Coenties Slip, and from thence, by Whitehall, northward. What do you see?\"\n",
        "]"
      ],
      "metadata": {
        "id": "TCJIscBf0DQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    return text\n",
        "\n",
        "cleaned_corpus = [clean_text(doc) for doc in corpus]\n",
        "print(cleaned_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv4CEpK20sRo",
        "outputId": "c9f38abd-1cf0-4f9d-ff06-cdc31c449e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and see the watery part of the world it is a way i have of driving off the spleen and regulating the circulation whenever i find myself growing grim about the mouth whenever it is a damp drizzly november in my soul whenever i find myself involuntarily pausing before coffin warehouses and bringing up the rear of every funeral i meet and especially whenever my hypos get such an upper hand of me that it requires a strong moral principle to prevent me from deliberately stepping into the street and methodically knocking people s hats off then i account it high time to get to sea as soon as i can this is my substitute for pistol and ball with a philosophical flourish cato throws himself upon his sword i quietly take to the ship there is nothing surprising in this if they but knew it almost all men in their degree some time or other cherish very nearly the same feelings towards the ocean with me there now is your insular city of the manhattoes belted round by wharves as indian isles by coral reefs commerce surrounds it with her surf right and left the streets take you waterward its extreme downtown is the battery where that noble mole is washed by waves and cooled by breezes which a few hours previous were out of sight of land look at the crowds of watergazers there circumambulate the city of a dreamy sabbath afternoon go from corlears hook to coenties slip and from thence by whitehall northward what do you see']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e29bc6",
        "outputId": "741b65c4-f000-4b06-f1cb-10dbf4561c8a"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def get_wordnet_pos(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def process_sentence(sentence):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    # POS tagging\n",
        "    pos_tags = pos_tag(tokens)\n",
        "\n",
        "    # Lemmatization with WordNet\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    results = []\n",
        "    for word, tag in pos_tags:\n",
        "        wordnet_pos = get_wordnet_pos(tag) or wordnet.NOUN\n",
        "        lemma = lemmatizer.lemmatize(word, pos=wordnet_pos)\n",
        "        results.append({\n",
        "            'token': word,\n",
        "            'nltk_pos': tag,\n",
        "            'wordnet_pos': wordnet_pos,\n",
        "            'lemma': lemma\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "input_sentence = \"Call me Ishmael. Some years ago—never mind how long precisely—having  drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, This is my substitute for pistol and ball. With a philosophical flourish Cato throws himself upon cherish very nearly th it with her surf. Right and left, the streets take you waterward. Its extreme downtown is the battery, where that noble mole is washed by waves, and cooled by breezes, which a few hours previous were out of sight of land. Look at the crowds of water-gazers there. Circumambulate the city of a dreamy Sabbath afternoon. Go from Corlears Hook to Coenties Slip, and from thence, by Whitehall, northward. What do you see?\"\n",
        "processed_results = process_sentence(input_sentence)\n",
        "\n",
        "# results\n",
        "for result in processed_results:\n",
        "    print(f\"Token: {result['token']}, NLTK POS: {result['nltk_pos']}, WordNet POS: {result['wordnet_pos']}, Lemma: {result['lemma']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Call, NLTK POS: VB, WordNet POS: v, Lemma: Call\n",
            "Token: me, NLTK POS: PRP, WordNet POS: n, Lemma: me\n",
            "Token: Ishmael, NLTK POS: NNP, WordNet POS: n, Lemma: Ishmael\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: Some, NLTK POS: DT, WordNet POS: n, Lemma: Some\n",
            "Token: years, NLTK POS: NNS, WordNet POS: n, Lemma: year\n",
            "Token: ago—never, NLTK POS: RB, WordNet POS: r, Lemma: ago—never\n",
            "Token: mind, NLTK POS: VB, WordNet POS: v, Lemma: mind\n",
            "Token: how, NLTK POS: WRB, WordNet POS: n, Lemma: how\n",
            "Token: long, NLTK POS: JJ, WordNet POS: a, Lemma: long\n",
            "Token: precisely—having, NLTK POS: NN, WordNet POS: n, Lemma: precisely—having\n",
            "Token: drizzly, NLTK POS: NN, WordNet POS: n, Lemma: drizzly\n",
            "Token: November, NLTK POS: NNP, WordNet POS: n, Lemma: November\n",
            "Token: in, NLTK POS: IN, WordNet POS: n, Lemma: in\n",
            "Token: my, NLTK POS: PRP$, WordNet POS: n, Lemma: my\n",
            "Token: soul, NLTK POS: NN, WordNet POS: n, Lemma: soul\n",
            "Token: ;, NLTK POS: :, WordNet POS: n, Lemma: ;\n",
            "Token: whenever, NLTK POS: WRB, WordNet POS: n, Lemma: whenever\n",
            "Token: I, NLTK POS: PRP, WordNet POS: n, Lemma: I\n",
            "Token: find, NLTK POS: VBP, WordNet POS: v, Lemma: find\n",
            "Token: myself, NLTK POS: PRP, WordNet POS: n, Lemma: myself\n",
            "Token: involuntarily, NLTK POS: RB, WordNet POS: r, Lemma: involuntarily\n",
            "Token: pausing, NLTK POS: VBG, WordNet POS: v, Lemma: pause\n",
            "Token: before, NLTK POS: IN, WordNet POS: n, Lemma: before\n",
            "Token: coffin, NLTK POS: NN, WordNet POS: n, Lemma: coffin\n",
            "Token: warehouses, NLTK POS: NNS, WordNet POS: n, Lemma: warehouse\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: This, NLTK POS: DT, WordNet POS: n, Lemma: This\n",
            "Token: is, NLTK POS: VBZ, WordNet POS: v, Lemma: be\n",
            "Token: my, NLTK POS: PRP$, WordNet POS: n, Lemma: my\n",
            "Token: substitute, NLTK POS: NN, WordNet POS: n, Lemma: substitute\n",
            "Token: for, NLTK POS: IN, WordNet POS: n, Lemma: for\n",
            "Token: pistol, NLTK POS: NN, WordNet POS: n, Lemma: pistol\n",
            "Token: and, NLTK POS: CC, WordNet POS: n, Lemma: and\n",
            "Token: ball, NLTK POS: NN, WordNet POS: n, Lemma: ball\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: With, NLTK POS: IN, WordNet POS: n, Lemma: With\n",
            "Token: a, NLTK POS: DT, WordNet POS: n, Lemma: a\n",
            "Token: philosophical, NLTK POS: JJ, WordNet POS: a, Lemma: philosophical\n",
            "Token: flourish, NLTK POS: JJ, WordNet POS: a, Lemma: flourish\n",
            "Token: Cato, NLTK POS: NNP, WordNet POS: n, Lemma: Cato\n",
            "Token: throws, NLTK POS: VBZ, WordNet POS: v, Lemma: throw\n",
            "Token: himself, NLTK POS: PRP, WordNet POS: n, Lemma: himself\n",
            "Token: upon, NLTK POS: IN, WordNet POS: n, Lemma: upon\n",
            "Token: cherish, NLTK POS: JJ, WordNet POS: a, Lemma: cherish\n",
            "Token: very, NLTK POS: RB, WordNet POS: r, Lemma: very\n",
            "Token: nearly, NLTK POS: RB, WordNet POS: r, Lemma: nearly\n",
            "Token: th, NLTK POS: VB, WordNet POS: v, Lemma: th\n",
            "Token: it, NLTK POS: PRP, WordNet POS: n, Lemma: it\n",
            "Token: with, NLTK POS: IN, WordNet POS: n, Lemma: with\n",
            "Token: her, NLTK POS: PRP$, WordNet POS: n, Lemma: her\n",
            "Token: surf, NLTK POS: NN, WordNet POS: n, Lemma: surf\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: Right, NLTK POS: NNP, WordNet POS: n, Lemma: Right\n",
            "Token: and, NLTK POS: CC, WordNet POS: n, Lemma: and\n",
            "Token: left, NLTK POS: VBD, WordNet POS: v, Lemma: leave\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: the, NLTK POS: DT, WordNet POS: n, Lemma: the\n",
            "Token: streets, NLTK POS: NNS, WordNet POS: n, Lemma: street\n",
            "Token: take, NLTK POS: VBP, WordNet POS: v, Lemma: take\n",
            "Token: you, NLTK POS: PRP, WordNet POS: n, Lemma: you\n",
            "Token: waterward, NLTK POS: RB, WordNet POS: r, Lemma: waterward\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: Its, NLTK POS: PRP$, WordNet POS: n, Lemma: Its\n",
            "Token: extreme, NLTK POS: JJ, WordNet POS: a, Lemma: extreme\n",
            "Token: downtown, NLTK POS: NN, WordNet POS: n, Lemma: downtown\n",
            "Token: is, NLTK POS: VBZ, WordNet POS: v, Lemma: be\n",
            "Token: the, NLTK POS: DT, WordNet POS: n, Lemma: the\n",
            "Token: battery, NLTK POS: NN, WordNet POS: n, Lemma: battery\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: where, NLTK POS: WRB, WordNet POS: n, Lemma: where\n",
            "Token: that, NLTK POS: DT, WordNet POS: n, Lemma: that\n",
            "Token: noble, NLTK POS: JJ, WordNet POS: a, Lemma: noble\n",
            "Token: mole, NLTK POS: NN, WordNet POS: n, Lemma: mole\n",
            "Token: is, NLTK POS: VBZ, WordNet POS: v, Lemma: be\n",
            "Token: washed, NLTK POS: VBN, WordNet POS: v, Lemma: wash\n",
            "Token: by, NLTK POS: IN, WordNet POS: n, Lemma: by\n",
            "Token: waves, NLTK POS: NNS, WordNet POS: n, Lemma: wave\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: and, NLTK POS: CC, WordNet POS: n, Lemma: and\n",
            "Token: cooled, NLTK POS: VBN, WordNet POS: v, Lemma: cool\n",
            "Token: by, NLTK POS: IN, WordNet POS: n, Lemma: by\n",
            "Token: breezes, NLTK POS: NNS, WordNet POS: n, Lemma: breeze\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: which, NLTK POS: WDT, WordNet POS: n, Lemma: which\n",
            "Token: a, NLTK POS: DT, WordNet POS: n, Lemma: a\n",
            "Token: few, NLTK POS: JJ, WordNet POS: a, Lemma: few\n",
            "Token: hours, NLTK POS: NNS, WordNet POS: n, Lemma: hour\n",
            "Token: previous, NLTK POS: JJ, WordNet POS: a, Lemma: previous\n",
            "Token: were, NLTK POS: VBD, WordNet POS: v, Lemma: be\n",
            "Token: out, NLTK POS: IN, WordNet POS: n, Lemma: out\n",
            "Token: of, NLTK POS: IN, WordNet POS: n, Lemma: of\n",
            "Token: sight, NLTK POS: NN, WordNet POS: n, Lemma: sight\n",
            "Token: of, NLTK POS: IN, WordNet POS: n, Lemma: of\n",
            "Token: land, NLTK POS: NN, WordNet POS: n, Lemma: land\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: Look, NLTK POS: VB, WordNet POS: v, Lemma: Look\n",
            "Token: at, NLTK POS: IN, WordNet POS: n, Lemma: at\n",
            "Token: the, NLTK POS: DT, WordNet POS: n, Lemma: the\n",
            "Token: crowds, NLTK POS: NN, WordNet POS: n, Lemma: crowd\n",
            "Token: of, NLTK POS: IN, WordNet POS: n, Lemma: of\n",
            "Token: water-gazers, NLTK POS: NNS, WordNet POS: n, Lemma: water-gazers\n",
            "Token: there, NLTK POS: RB, WordNet POS: r, Lemma: there\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: Circumambulate, NLTK POS: VB, WordNet POS: v, Lemma: Circumambulate\n",
            "Token: the, NLTK POS: DT, WordNet POS: n, Lemma: the\n",
            "Token: city, NLTK POS: NN, WordNet POS: n, Lemma: city\n",
            "Token: of, NLTK POS: IN, WordNet POS: n, Lemma: of\n",
            "Token: a, NLTK POS: DT, WordNet POS: n, Lemma: a\n",
            "Token: dreamy, NLTK POS: JJ, WordNet POS: a, Lemma: dreamy\n",
            "Token: Sabbath, NLTK POS: NNP, WordNet POS: n, Lemma: Sabbath\n",
            "Token: afternoon, NLTK POS: NN, WordNet POS: n, Lemma: afternoon\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: Go, NLTK POS: VB, WordNet POS: v, Lemma: Go\n",
            "Token: from, NLTK POS: IN, WordNet POS: n, Lemma: from\n",
            "Token: Corlears, NLTK POS: NNP, WordNet POS: n, Lemma: Corlears\n",
            "Token: Hook, NLTK POS: NNP, WordNet POS: n, Lemma: Hook\n",
            "Token: to, NLTK POS: TO, WordNet POS: n, Lemma: to\n",
            "Token: Coenties, NLTK POS: NNP, WordNet POS: n, Lemma: Coenties\n",
            "Token: Slip, NLTK POS: NNP, WordNet POS: n, Lemma: Slip\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: and, NLTK POS: CC, WordNet POS: n, Lemma: and\n",
            "Token: from, NLTK POS: IN, WordNet POS: n, Lemma: from\n",
            "Token: thence, NLTK POS: NN, WordNet POS: n, Lemma: thence\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: by, NLTK POS: IN, WordNet POS: n, Lemma: by\n",
            "Token: Whitehall, NLTK POS: NNP, WordNet POS: n, Lemma: Whitehall\n",
            "Token: ,, NLTK POS: ,, WordNet POS: n, Lemma: ,\n",
            "Token: northward, NLTK POS: RB, WordNet POS: r, Lemma: northward\n",
            "Token: ., NLTK POS: ., WordNet POS: n, Lemma: .\n",
            "Token: What, NLTK POS: WP, WordNet POS: n, Lemma: What\n",
            "Token: do, NLTK POS: VBP, WordNet POS: v, Lemma: do\n",
            "Token: you, NLTK POS: PRP, WordNet POS: n, Lemma: you\n",
            "Token: see, NLTK POS: VB, WordNet POS: v, Lemma: see\n",
            "Token: ?, NLTK POS: ., WordNet POS: n, Lemma: ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmKaJIgF2B27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ea9d45"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "This notebook demonstrates a basic NLP pipeline. It includes steps for text cleaning, tokenization, POS tagging, and lemmatization. The code successfully processes a sample text from Moby Dick. The outputs show the tokenized words, their NLTK POS tags, the corresponding WordNet POS tags, and their lemmas."
      ]
    }
  ]
}