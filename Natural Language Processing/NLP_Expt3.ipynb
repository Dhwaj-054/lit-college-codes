{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzZKILbMy7R2",
        "outputId": "1b981a58-a859-4967-d432-fbc050e38683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP Expt 3\n",
            "Dhwaj Jain S012\n"
          ]
        }
      ],
      "source": [
        "print(\"NLP Expt 3\")\n",
        "print(\"Dhwaj Jain S012\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic_transliteration\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "word = \"bachchaa\"\n",
        "hindi\t= transliterate(word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "print(hindi)\n",
        "guj = transliterate(word, sanscript.ITRANS, sanscript.GUJARATI)\n",
        "print(guj)\n",
        "eng\t= transliterate(word, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
        "print(eng)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd97S1eRzBSb",
        "outputId": "acfd06c4-c7e7-4d21-846b-7acf22ae7b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: indic_transliteration in /usr/local/lib/python3.12/dist-packages (2.3.74)\n",
            "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.12/dist-packages (from indic_transliteration) (2.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from indic_transliteration) (2024.11.6)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from indic_transliteration) (0.16.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from indic_transliteration) (0.10.2)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.12/dist-packages (from indic_transliteration) (5.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic_transliteration) (8.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from typer->indic_transliteration) (4.15.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic_transliteration) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic_transliteration) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic_transliteration) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic_transliteration) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic_transliteration) (0.1.2)\n",
            "बच्चा\n",
            "બચ્ચા\n",
            "bachchaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_plural_hindi(word):\n",
        "  root = word[:-2]\n",
        "  output = root\n",
        "  output += transliterate(\"oM\", sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "  return output\n",
        "\n",
        "word = \"bachchaa\"\n",
        "word = transliterate(word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "print(word)\n",
        "plural = get_plural_hindi(word)\n",
        "print(plural)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV-9AdRSzokI",
        "outputId": "75da6ffd-d46f-4b2a-b353-71e846c3694d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "बच्चा\n",
            "बच्ओं\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_plural_gujrati(word):\n",
        "  root = word[:-1]\n",
        "  output = root\n",
        "  output += transliterate(\"iyo\", sanscript.ITRANS, sanscript.GUJARATI)\n",
        "  return output\n",
        "\n",
        "word = \"chhokarii\"\n",
        "word = transliterate(word, sanscript.ITRANS, sanscript.GUJARATI)\n",
        "print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_QhMz9f0OqQ",
        "outputId": "034d223f-ab34-491c-a7e2-63aa0d23459a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "છોકરી\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(word)\n",
        "plural = get_plural_gujrati(word)\n",
        "print(plural)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AM_nIo_0fr6",
        "outputId": "4cc42de0-b815-4793-937d-567a656d3b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "છોકરી\n",
            "છોકરઇયો\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_past_english(word):\n",
        "  root = word[:-2]\n",
        "  output = root\n",
        "  output += \"ed\"\n",
        "  return output\n",
        "\n",
        "word = \"player\"\n",
        "print(word)\n",
        "past = get_past_english(word)\n",
        "print(past)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXSKjYPd00ds",
        "outputId": "72032d9f-fd69-41cf-80c4-f646fcf5c19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "player\n",
            "played\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(word):\n",
        "  for suffix in [\"ing\", \"ed\", \"es\"]:\n",
        "    if word.endswith(suffix):\n",
        "      word = word[:-len(suffix)]\n",
        "\n",
        "  for prefix in [\"un\", \"re\", \"dis\"]:\n",
        "    if word.startswith(prefix):\n",
        "      word = word[len(prefix):]\n",
        "\n",
        "  if word.endswith(\"ies\"):\n",
        "    word = word[:-3] + \"y\"\n",
        "  elif word.endswith(\"s\"):\n",
        "    word = word[:-1]\n",
        "  return word\n",
        "\n",
        "def stem_sentence(sentence):\n",
        "  words = sentence.split()\n",
        "  stemmed_words = [stem(word) for word in words]\n",
        "  stemmed_sentence = \" \".join(stemmed_words)\n",
        "  return stemmed_sentence"
      ],
      "metadata": {
        "id": "hyXmXSqy0_yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The striped bats are hanging on their feet for best\"\n",
        "stemmed_sentence = stem_sentence(sentence)\n",
        "\n",
        "print(\"Original sentence: \", sentence)\n",
        "print(\"Stemmed words:\", stemmed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbRi35GN1pXI",
        "outputId": "b0f0631a-3915-4b65-960d-54056cd410f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  The striped bats are hanging on their feet for best\n",
            "Stemmed words: The strip bat are hang on their feet for best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "sentence = \"The striped bats are hanging on their feet for beat\"\n",
        "words = sentence.split()\n",
        "\n",
        "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
        "stemmed_text = \" \".join(stemmed_words)\n",
        "\n",
        "# Print the results\n",
        "print(\"Original sentence: \", sentence)\n",
        "print(\"Stemmed words:\", stemmed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWyaExoD2lVZ",
        "outputId": "a2c4b17e-6cca-4aeb-c02d-4537f61a07b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  The striped bats are hanging on their feet for beat\n",
            "Stemmed words: the stripe bat are hang on their feet for beat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515c3139"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "This experiment successfully performed Morphological Analysis by demonstrating how words are composed of morphemes, the smallest meaningful units. The objective was met by applying rules to decompose a word (like बच्चों) into its root (बच्चा) and grammatical features (like plural, oblique, and suffix ओं), thereby revealing its linguistic properties. This analysis confirmed that morphological analysis is a fundamental step in NLP for understanding word structure, generating word forms (inflection), and improving language model accuracy by grouping words into paradigm classes (e.g., बच्चा and लड़का), which share common inflectional rules. The use of libraries like Polyglot further aids in automating this complex linguistic process.\n",
        "\n",
        "This notebook explored basic string manipulation for language processing, including transliteration between Indic scripts and ITRANS, simple custom functions for generating plurals and past tense forms, and two different approaches to word stemming (a custom function and NLTK's PorterStemmer). These examples demonstrate fundamental techniques for transforming words and sentences programmatically, often used in Natural Language Processing tasks."
      ]
    }
  ]
}