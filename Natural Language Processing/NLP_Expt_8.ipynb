{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odZ1mqOUD-GX",
        "outputId": "143bbd87-de77-4298-8795-f50a73b25fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP Expt 8\n",
            "Dhwaj Jain S012\n"
          ]
        }
      ],
      "source": [
        "print(\"NLP Expt 8\")\n",
        "print(\"Dhwaj Jain S012\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVcPAAvVD_gn",
        "outputId": "a4b2e889-0a6b-492d-cd52-5cf9238602d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords and punctuations\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "fuCteXhWEQS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(list1, list2):\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    if len(union) == 0:\n",
        "        return 0\n",
        "    return len(intersection) / len(union)\n"
      ],
      "metadata": {
        "id": "ZYeA2sPvERsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lcs(X, Y):\n",
        "    m = len(X)\n",
        "    n = len(Y)\n",
        "    L = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            if X[i] == Y[j]:\n",
        "                L[i + 1][j + 1] = L[i][j] + 1\n",
        "            else:\n",
        "                L[i + 1][j + 1] = max(L[i + 1][j], L[i][j + 1])\n",
        "\n",
        "    return L[m][n]\n"
      ],
      "metadata": {
        "id": "W2J3Sz4VEVSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example original text\n",
        "original_text = \"\"\"\n",
        "Natural Language Processing technologies can be effectively used to detect plagiarism in texts.\n",
        "\"\"\"\n",
        "\n",
        "# Near copy suspicious text (almost same)\n",
        "near_copy = \"\"\"\n",
        "Natural language processing technologies are effectively used to detect plagiarism in texts.\n",
        "\"\"\"\n",
        "\n",
        "# Lightly revised suspicious text (some paraphrasing)\n",
        "lightly_revised = \"\"\"\n",
        "Techniques in natural language processing help in identifying plagiarism within documents.\n",
        "\"\"\"\n",
        "\n",
        "# Heavily revised suspicious text (more paraphrasing)\n",
        "heavily_revised = \"\"\"\n",
        "Methods of analyzing human language enable detection of copied content in written materials.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "AeIWQoUGEW0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = {\n",
        "    \"Near Copy\": near_copy,\n",
        "    \"Lightly Revised\": lightly_revised,\n",
        "    \"Heavily Revised\": heavily_revised\n",
        "}\n",
        "\n",
        "print(\"Original text tokens:\", preprocess_text(original_text))\n",
        "\n",
        "for label, suspicious_text in texts.items():\n",
        "    original_tokens = preprocess_text(original_text)\n",
        "    suspicious_tokens = preprocess_text(suspicious_text)\n",
        "\n",
        "    jaccard_score = jaccard_similarity(original_tokens, suspicious_tokens)\n",
        "    lcs_length = lcs(original_tokens, suspicious_tokens)\n",
        "    lcs_ratio = lcs_length / max(len(original_tokens), len(suspicious_tokens))\n",
        "\n",
        "    print(f\"\\n--- {label} ---\")\n",
        "    print(f\"Jaccard Similarity: {jaccard_score:.3f}\")\n",
        "    print(f\"LCS Length: {lcs_length}\")\n",
        "    print(f\"LCS Ratio: {lcs_ratio:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdJrbdroEX_I",
        "outputId": "0fb02809-7154-409a-c877-398be93cfd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text tokens: ['natural', 'language', 'processing', 'technologies', 'effectively', 'used', 'detect', 'plagiarism', 'texts']\n",
            "\n",
            "--- Near Copy ---\n",
            "Jaccard Similarity: 1.000\n",
            "LCS Length: 9\n",
            "LCS Ratio: 1.000\n",
            "\n",
            "--- Lightly Revised ---\n",
            "Jaccard Similarity: 0.286\n",
            "LCS Length: 4\n",
            "LCS Ratio: 0.444\n",
            "\n",
            "--- Heavily Revised ---\n",
            "Jaccard Similarity: 0.056\n",
            "LCS Length: 1\n",
            "LCS Ratio: 0.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce572cae",
        "outputId": "b7da39ef-4eab-49cb-bb92-778815250abb"
      },
      "source": [
        "# New example texts\n",
        "high_plagiarism_text = \"\"\"\n",
        "Natural Language Processing technologies can be effectively used to detect plagiarism in texts. Thus we understand how important NLP tech is and how useful for our plagarism checks it is. Used in research papers checking and assignments checking too.\n",
        "\"\"\"\n",
        "\n",
        "low_plagiarism_text = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog. We thus understand why it jumps over the lazy dog.\n",
        "\"\"\"\n",
        "\n",
        "new_texts = {\n",
        "    \"High Plagiarism\": high_plagiarism_text,\n",
        "    \"Low Plagiarism\": low_plagiarism_text\n",
        "}\n",
        "\n",
        "print(\"\\n--- Testing with new examples ---\")\n",
        "for label, suspicious_text in new_texts.items():\n",
        "    original_tokens = preprocess_text(original_text)\n",
        "    suspicious_tokens = preprocess_text(suspicious_text)\n",
        "\n",
        "    jaccard_score = jaccard_similarity(original_tokens, suspicious_tokens)\n",
        "    lcs_length = lcs(original_tokens, suspicious_tokens)\n",
        "    lcs_ratio = lcs_length / max(len(original_tokens), len(suspicious_tokens))\n",
        "\n",
        "    print(f\"\\n--- {label} ---\")\n",
        "    print(f\"Jaccard Similarity: {jaccard_score:.3f}\")\n",
        "    print(f\"LCS Length: {lcs_length}\")\n",
        "    print(f\"LCS Ratio: {lcs_ratio:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing with new examples ---\n",
            "\n",
            "--- High Plagiarism ---\n",
            "Jaccard Similarity: 0.429\n",
            "LCS Length: 9\n",
            "LCS Ratio: 0.391\n",
            "\n",
            "--- Low Plagiarism ---\n",
            "Jaccard Similarity: 0.000\n",
            "LCS Length: 0\n",
            "LCS Ratio: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkBeX3SiEcyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ed3e9d7",
        "outputId": "84361aa2-2cc6-40a1-a057-5f7c0067d3ed"
      },
      "source": [
        "!pip install PyMuPDF\n",
        "import fitz # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {e}\")\n",
        "        text = None # Indicate failure\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38af2b5"
      },
      "source": [
        "Now you can upload your two research papers (PDFs) and use the `extract_text_from_pdf` function to load their content into variables.\n",
        "\n",
        "For example, after uploading `paper1.pdf` and `paper2.pdf`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "82ae3ce2",
        "outputId": "1d26eb22-da35-4686-f2a1-a0dd39a94361"
      },
      "source": [
        "# Example usage (replace with your uploaded file paths)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Replace with the actual uploaded file names\n",
        "paper1_name = '2506.00256v1.pdf'\n",
        "paper2_name = '2405.12819v2.pdf'\n",
        "\n",
        "original_paper_1 = extract_text_from_pdf(paper1_name)\n",
        "original_paper_2 = extract_text_from_pdf(paper2_name)\n",
        "\n",
        "# # You can combine the text from both papers into a single original text if needed\n",
        "combined_original_text = \"\"\n",
        "if original_paper_1:\n",
        "    combined_original_text += original_paper_1\n",
        "    print(\"Successfully loaded text from paper 1\")\n",
        "else:\n",
        "    print(f\"Failed to load text from {paper1_name}\")\n",
        "\n",
        "if original_paper_2:\n",
        "    if combined_original_text: # Add a newline if we already added text from paper 1\n",
        "        combined_original_text += \"\\n\"\n",
        "    combined_original_text += original_paper_2\n",
        "    print(\"Successfully loaded text from paper 2\")\n",
        "else:\n",
        "    print(f\"Failed to load text from {paper2_name}\")\n",
        "\n",
        "\n",
        "if combined_original_text:\n",
        "  print(\"\\nCombined original text is ready for plagiarism check.\")\n",
        "else:\n",
        "  print(\"\\nCould not load text from the original papers.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-616f0848-cfde-4ef1-9599-d00fa4e35277\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-616f0848-cfde-4ef1-9599-d00fa4e35277\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2506.00256v1.pdf to 2506.00256v1 (2).pdf\n",
            "Saving 2405.12819v2.pdf to 2405.12819v2 (2).pdf\n",
            "Successfully loaded text from paper 1\n",
            "Successfully loaded text from paper 2\n",
            "\n",
            "Combined original text is ready for plagiarism check.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "2539d782",
        "outputId": "55653537-640b-47be-898d-3c8a1e155735"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming the third paper is the only new file uploaded\n",
        "third_paper_name = list(uploaded.keys())[0]\n",
        "third_paper_path = third_paper_name\n",
        "\n",
        "suspicious_paper = extract_text_from_pdf(third_paper_path)\n",
        "\n",
        "if suspicious_paper:\n",
        "    print(f\"Successfully loaded text from {third_paper_name}\")\n",
        "\n",
        "    # Ensure combined_original_text is defined and has content\n",
        "    if 'combined_original_text' in locals() and combined_original_text:\n",
        "        original_tokens = preprocess_text(combined_original_text)\n",
        "        suspicious_tokens = preprocess_text(suspicious_paper)\n",
        "\n",
        "        jaccard_score = jaccard_similarity(original_tokens, suspicious_tokens)\n",
        "        lcs_length = lcs(original_tokens, suspicious_tokens)\n",
        "        lcs_ratio = lcs_length / max(len(original_tokens), len(suspicious_tokens)) if max(len(original_tokens), len(suspicious_tokens)) > 0 else 0\n",
        "\n",
        "        print(f\"\\n--- Plagiarism Check Results for {third_paper_name} ---\")\n",
        "        print(f\"Jaccard Similarity: {jaccard_score:.3f}\")\n",
        "        print(f\"LCS Length: {lcs_length}\")\n",
        "        print(f\"LCS Ratio: {lcs_ratio:.3f}\")\n",
        "    else:\n",
        "        print(\"Combined original text is not available. Please ensure you have loaded and combined the original papers.\")\n",
        "else:\n",
        "    print(\"Failed to load text from the suspicious paper.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a7c24b0-19a5-4598-863e-093e28e22e51\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a7c24b0-19a5-4598-863e-093e28e22e51\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Merged_Research_Paper.pdf to Merged_Research_Paper (1).pdf\n",
            "Successfully loaded text from Merged_Research_Paper (1).pdf\n",
            "\n",
            "--- Plagiarism Check Results for Merged_Research_Paper (1).pdf ---\n",
            "Jaccard Similarity: 0.637\n",
            "LCS Length: 14984\n",
            "LCS Ratio: 0.729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure original_tokens and suspicious_tokens are available from previous steps\n",
        "\n",
        "# Calculate LCS Length and Ratio\n",
        "if 'original_tokens' in locals() and 'suspicious_tokens' in locals():\n",
        "    lcs_length = lcs(original_tokens, suspicious_tokens)\n",
        "    lcs_ratio = lcs_length / max(len(original_tokens), len(suspicious_tokens)) if max(len(original_tokens), len(suspicious_tokens)) > 0 else 0\n",
        "\n",
        "    print(\"\\n--- LCS Comparison ---\")\n",
        "    print(f\"LCS Length: {lcs_length}\")\n",
        "    print(f\"LCS Ratio: {lcs_ratio:.3f}\")\n",
        "\n",
        "    # Calculate Cosine Similarity\n",
        "    from collections import Counter\n",
        "    import numpy as np\n",
        "\n",
        "    def cosine_similarity(list1, list2):\n",
        "        vec1 = Counter(list1)\n",
        "        vec2 = Counter(list2)\n",
        "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "        sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "        sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "        denominator = np.sqrt(sum1) * np.sqrt(sum2)\n",
        "\n",
        "        if not denominator:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return float(numerator) / denominator\n",
        "\n",
        "    cosine_sim_score = cosine_similarity(original_tokens, suspicious_tokens)\n",
        "\n",
        "    print(\"\\n--- Cosine Similarity ---\")\n",
        "    print(f\"Cosine Similarity: {cosine_sim_score:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"Original and/or suspicious text tokens not available. Please ensure previous cells have been run.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U72LVaNN6DR",
        "outputId": "370d86af-0011-4bc9-8236-225d526be25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LCS Comparison ---\n",
            "LCS Length: 14984\n",
            "LCS Ratio: 0.729\n",
            "\n",
            "--- Cosine Similarity ---\n",
            "Cosine Similarity: 0.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1a7kBfPq6C_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9c4f561"
      },
      "source": [
        "**Conclusion:**\n",
        "\n",
        "This notebook demonstrates a basic approach to plagiarism detection using NLP techniques. We calculated Jaccard Similarity, Longest Common Subsequence (LCS) Length and Ratio, and Cosine Similarity between a combined original text and a suspicious text. The high scores across these metrics indicate a significant overlap between the documents, suggesting a high likelihood of plagiarism in the suspicious paper when compared to the combined original papers. This analysis provides quantitative measures to assess the degree of similarity, which is a crucial step in identifying potential plagiarism."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRPuOZCA6DWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the end"
      ],
      "metadata": {
        "id": "0xkpN0kr6EXV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X6pixMsk5_bT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}